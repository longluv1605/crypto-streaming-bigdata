services:
    zookeeper:
        image: confluentinc/cp-zookeeper:7.3.0
        container_name: zookeeper
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181

    # kafka:
    #     image: confluentinc/cp-kafka:7.3.0
    #     container_name: kafka
    #     ports:
    #         - "9093:9092"
    #     environment:
    #         KAFKA_BROKER_ID: 1
    #         KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    #         KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093
    #         KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
    #         KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    #     depends_on:
    #         - zookeeper

    hbase:
        build: 
            dockerfile: ./Dockerfile.hbase
        container_name: hbase
        ports:
            - "2181:2181"
            - "16010:16010"
            - "8085:8085"
        environment:
            HBASE_ZOOKEEPER_QUORUM: zookeeper
            HBASE_ZOOKEEPER_PROPERTY_CLIENTPORT: 2181
        depends_on:
            - zookeeper

    # spark-master:
    #     image: bitnami/spark:latest
    #     container_name: spark-master
    #     environment:
    #         - SPARK_MODE=master
    #         - SPARK_RPC_AUTHENTICATION_ENABLED=no
    #     ports:
    #         - "7077:7077"
    #         - "8080:8080"
    #     volumes:
    #         - ./streaming_layer:/app
    #     # networks:
    #     #     - spark-net

    # spark-worker:
    #     image: bitnami/spark:latest
    #     container_name: spark-worker
    #     environment:
    #         - SPARK_MODE=worker
    #         - SPARK_MASTER_URL=spark://spark-master:7077
    #     depends_on:
    #         - spark-master
    #     # networks:
    #     #     - spark-net

    # ingestion:
    #     build:
    #         # context: ./ingestion_layer
    #         dockerfile: ./Dockerfile.api
    #     container_name: ingestion
    #     depends_on:
    #         - kafka

    # spark-job:
    #     build:
    #         # context: ./streaming_layer
    #         dockerfile: ./Dockerfile.spark
    #     container_name: spark-job
    #     depends_on:
    #         - kafka
    #         - spark-master
    #         - hbase

# networks:
#     spark-net:
#         driver: bridge
