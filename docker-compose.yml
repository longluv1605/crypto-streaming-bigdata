services:
    zookeeper:
        image: confluentinc/cp-zookeeper:7.3.0
        container_name: zookeeper
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
        healthcheck:
            test:
                [
                    "CMD",
                    "echo",
                    "ruok",
                    "|",
                    "nc",
                    "localhost",
                    "2181",
                    "|",
                    "grep",
                    "imok",
                ]
            interval: 10s
            timeout: 5s
            retries: 3

    kafka:
        image: confluentinc/cp-kafka:7.3.0
        container_name: kafka
        ports:
            - "9093:9092"
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
        depends_on:
            zookeeper:
                condition: service_healthy
        healthcheck:
            test: ["CMD", "bash", "-c", "echo > /dev/tcp/localhost/9092"]
            interval: 10s
            timeout: 5s
            retries: 3

    hbase:
        build:
            dockerfile: ./Dockerfile.hbase
        container_name: hbase
        ports:
            - "2181:2181"
            - "16010:16010"
            - "8085:8085"
        environment:
            HBASE_ZOOKEEPER_QUORUM: zookeeper
            HBASE_ZOOKEEPER_PROPERTY_CLIENTPORT: 2181
        depends_on:
            zookeeper:
                condition: service_healthy
        # healthcheck:
        #     test: >
        #         bash -c "
        #         echo 'status' | hbase shell 2>/dev/null | grep -q 'ACTIVE' &&
        #         echo 'list \"real_stream\"' | hbase shell 2>/dev/null | grep 'real_stream' >/dev/null
        #         "
        #     interval: 30s
        #     timeout: 10s
        #     retries: 30
        #     start_period: 30s

    # spark-master:
    #     image: bitnami/spark:latest
    #     container_name: spark-master
    #     environment:
    #         - SPARK_MODE=master
    #         - SPARK_RPC_AUTHENTICATION_ENABLED=no
    #     ports:
    #         - "7077:7077"
    #         - "8080:8080"
    #     volumes:
    #         - ./streaming_layer:/app
    #     # networks:
    #     #     - spark-net

    # spark-worker:
    #     image: bitnami/spark:latest
    #     container_name: spark-worker
    #     environment:
    #         - SPARK_MODE=worker
    #         - SPARK_MASTER_URL=spark://spark-master:7077
    #     depends_on:
    #         - spark-master
    #     # networks:
    #     #     - spark-net

    ingestion:
        build:
            # context: ./ingestion_layer
            dockerfile: ./Dockerfile.api
        container_name: ingestion
        depends_on:
            kafka:
                condition: service_healthy

    streaming-job:
        build:
            # context: ./streaming_layer
            dockerfile: ./Dockerfile.streaming
        container_name: streaming-job
        depends_on:
            - hbase
            - kafka
            # kafka:
            #     condition: service_healthy
            # hbase:
            #     condition: service_healthy
# networks:
#     spark-net:
#         driver: bridge
